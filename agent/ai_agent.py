import warnings
import os
import asyncio
import time
import traceback
import concurrent.futures
from typing import Dict, Any, List, Optional, Generator
from agent.RAG.retriever import rag_search
from agent.sql.attraction_ezqa_service import myanswer

# æŠ‘åˆ¶LangChainå¼ƒç”¨è­¦å‘Š
warnings.filterwarnings("ignore", category=DeprecationWarning)

from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, AIMessage, SystemMessage, BaseMessage
from dotenv import load_dotenv

# MCP å·¥å…·å¯¼å…¥
try:
    from mcp import ClientSession, StdioServerParameters
    from mcp.client.stdio import stdio_client
    from langchain_mcp_adapters.tools import load_mcp_tools
    from langgraph.prebuilt import create_react_agent
    MCP_AVAILABLE = True
except ImportError:
    print("MCPå·¥å…·ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ¨¡å¼")
    MCP_AVAILABLE = False

# PDFç”Ÿæˆç±»å’Œæç¤ºè¯å¯¼å…¥
from agent.pdf_generator import PDFGeneratorTool
try:
    from .prompts import (
        GENERAL_SYSTEM_PROMPT, TRAVEL_SYSTEM_PROMPT, PDF_PROMPT,
        INFORMATION_COLLECTOR_PROMPT, ITINERARY_PLANNER_PROMPT
    )
    from .redis_memory import get_redis_memory_manager, SimpleMemory as RedisSimpleMemory
except ImportError:
    from agent.prompts import (
        GENERAL_SYSTEM_PROMPT, TRAVEL_SYSTEM_PROMPT, PDF_PROMPT,
        INFORMATION_COLLECTOR_PROMPT, ITINERARY_PLANNER_PROMPT
    )
    from agent.redis_memory import get_redis_memory_manager, SimpleMemory as RedisSimpleMemory

# =============================================================================
# 1. Component and Utility Classes (The Foundation)
# è¿™äº›æ˜¯æ„æˆç³»ç»Ÿçš„åŸºç¡€æ¨¡å—ï¼Œæ¯ä¸ªç±»èŒè´£å•ä¸€ã€‚
# =============================================================================



class ConfigManager:
    """ç»Ÿä¸€é…ç½®ç®¡ç†"""
    def __init__(self):
        load_dotenv()
        self.api_key = os.getenv("OPENAI_API_KEY")
        self.base_url = os.getenv("OPENAI_API_URL")
        self.searchapi_key = os.getenv("SEARCHAPI_API_KEY", "")
        self.mcp_server_path = "agent/mcp_server.py"
        
        if not self.api_key:
            raise ValueError("æœªé…ç½®OpenAI APIå¯†é’¥")
    
    def get_server_params(self) -> StdioServerParameters:
        """è·å–MCPæœåŠ¡å™¨å‚æ•°"""
        return StdioServerParameters(
            command="python",
            args=[self.mcp_server_path],
            env={"SEARCHAPI_API_KEY": self.searchapi_key}
        )

class LLMFactory:
    """LLMå®ä¾‹å·¥å‚"""
    def __init__(self, config: ConfigManager):
        self.config = config
    
    def create_llm(self, model: str = "gpt-4.1-nano", temperature: float = 0.1, 
                   streaming: bool = False) -> ChatOpenAI:
        """åˆ›å»ºLLMå®ä¾‹"""
        return ChatOpenAI(
            api_key=self.config.api_key,
            model=model,
            base_url=self.config.base_url,
            temperature=temperature,
            streaming=streaming
        )

class MCPManager:
    """MCPè¿æ¥å’Œå·¥å…·ç®¡ç†"""
    def __init__(self, config: ConfigManager):
        self.config = config
    
    async def load_tools_async(self) -> List[Any]:
        """å¼‚æ­¥åŠ è½½MCPå·¥å…·"""
        try:
            # ç›´æ¥å¯¼å…¥æœ¬åœ°MCPå·¥å…·ï¼Œé¿å…MCPåè®®åŠ è½½é—®é¢˜
            from agent.mcp_server import get_current_time, search_google, search_google_maps, search_google_flights, search_google_hotels
            from langchain.tools import tool
            
            # åˆ›å»ºLangChainå·¥å…·åŒ…è£…å™¨
            tools = []
            
            # åŒ…è£…get_current_time
            @tool
            async def get_current_time_tool(format: str = "iso") -> str:
                """è·å–å½“å‰ç³»ç»Ÿæ—¶é—´å’Œæ—…è¡Œæ—¥æœŸå»ºè®®"""
                result = await get_current_time(format=format)
                if isinstance(result, dict) and "date" in result:
                    return f"å½“å‰æ—¶é—´: {result['date']}"
                else:
                    return str(result)
            
            # åŒ…è£…search_google
            @tool
            async def search_google_tool(q: str) -> str:
                """æœç´¢Googleæœç´¢ç»“æœ"""
                result = await search_google(q=q)
                if isinstance(result, dict):
                    if "error" in result:
                        return f"æœç´¢å¤±è´¥: {result['error']}"
                    elif "organic_results" in result:
                        results = result["organic_results"][:5]  # å–å‰5ä¸ªç»“æœ
                        search_summary = []
                        for r in results:
                            title = r.get('title', '')
                            snippet = r.get('snippet', '')[:100]  # æˆªå–å‰100å­—ç¬¦
                            search_summary.append(f"{title}: {snippet}")
                        return f"æ‰¾åˆ° {len(results)} ä¸ªæœç´¢ç»“æœ:\n" + "\n".join(search_summary)
                    else:
                        return f"æœç´¢å®Œæˆï¼Œç»“æœ: {list(result.keys())}"
                else:
                    return str(result)
            
            # åŒ…è£…search_google_maps
            @tool
            async def search_google_maps_tool(query: str) -> str:
                """æœç´¢Googleåœ°å›¾ä¸Šçš„åœ°ç‚¹æˆ–æœåŠ¡"""
                result = await search_google_maps(query=query)
                if isinstance(result, dict):
                    if "error" in result:
                        return f"åœ°å›¾æœç´¢å¤±è´¥: {result['error']}"
                    elif "local_results" in result:
                        results = result["local_results"][:5]  # å–å‰5ä¸ªç»“æœ
                        map_summary = []
                        for r in results:
                            title = r.get('title', '')
                            address = r.get('address', '')
                            rating = r.get('rating', '')
                            map_summary.append(f"{title} - {address} - è¯„åˆ†:{rating}")
                        return f"æ‰¾åˆ° {len(results)} ä¸ªåœ°ç‚¹:\n" + "\n".join(map_summary)
                    else:
                        return f"åœ°å›¾æœç´¢å®Œæˆï¼Œç»“æœ: {list(result.keys())}"
                else:
                    return str(result)
            
            # åŒ…è£…search_google_flights
            @tool
            async def search_google_flights_tool(departure_id: str, arrival_id: str, outbound_date: str, flight_type: str = "round_trip", return_date: str = None) -> str:
                """æœç´¢Googleèˆªç­ä¿¡æ¯"""
                # è‡ªåŠ¨å¤„ç†æ—¥æœŸï¼Œå¦‚æœæ²¡æœ‰æä¾›æˆ–æ—¥æœŸä¸åˆç†
                from datetime import datetime, timedelta
                today = datetime.now()
                
                if not outbound_date:
                    outbound_date = (today + timedelta(days=7)).strftime("%Y-%m-%d")
                else:
                    try:
                        outbound = datetime.strptime(outbound_date, "%Y-%m-%d")
                        if outbound.date() < today.date():
                            outbound_date = (today + timedelta(days=7)).strftime("%Y-%m-%d")
                    except ValueError:
                        outbound_date = (today + timedelta(days=7)).strftime("%Y-%m-%d")
                
                if flight_type == "round_trip" and not return_date:
                    return_date = (today + timedelta(days=14)).strftime("%Y-%m-%d")
                
                result = await search_google_flights(
                    departure_id=departure_id,
                    arrival_id=arrival_id,
                    outbound_date=outbound_date,
                    flight_type=flight_type,
                    return_date=return_date
                )
                if isinstance(result, dict):
                    if "error" in result:
                        return f"èˆªç­æœç´¢å¤±è´¥: {result['error']}"
                    elif "flights" in result:
                        flights = result["flights"][:5]  # å–å‰5ä¸ªèˆªç­
                        flight_summary = []
                        for flight in flights:
                            airline = flight.get('airline', '')
                            departure_time = flight.get('departure_time', '')
                            arrival_time = flight.get('arrival_time', '')
                            price = flight.get('price', '')
                            flight_summary.append(f"{airline} - {departure_time}åˆ°{arrival_time} - {price}")
                        return f"æ‰¾åˆ° {len(flights)} ä¸ªèˆªç­:\n" + "\n".join(flight_summary)
                    else:
                        return f"èˆªç­æœç´¢å®Œæˆï¼Œç»“æœ: {list(result.keys())}"
                else:
                    return str(result)
            
            # åŒ…è£…search_google_hotels
            @tool
            async def search_google_hotels_tool(q: str, check_in_date: str = None, check_out_date: str = None) -> str:
                """æœç´¢Googleé…’åº—ä¿¡æ¯"""
                # å¦‚æœæ²¡æœ‰æä¾›æ—¥æœŸï¼Œè‡ªåŠ¨ä½¿ç”¨åˆç†çš„æœªæ¥æ—¥æœŸ
                from datetime import datetime, timedelta
                today = datetime.now()
                
                if not check_in_date:
                    check_in_date = (today + timedelta(days=1)).strftime("%Y-%m-%d")
                if not check_out_date:
                    check_out_date = (today + timedelta(days=3)).strftime("%Y-%m-%d")
                
                # éªŒè¯æ—¥æœŸæ˜¯å¦åˆç†ï¼ˆä¸èƒ½æ˜¯è¿‡å»æ—¥æœŸï¼‰
                try:
                    check_in = datetime.strptime(check_in_date, "%Y-%m-%d")
                    if check_in.date() < today.date():
                        # å¦‚æœå…¥ä½æ—¥æœŸæ˜¯è¿‡å»ï¼Œè°ƒæ•´ä¸ºæ˜å¤©
                        check_in_date = (today + timedelta(days=1)).strftime("%Y-%m-%d")
                        check_out_date = (today + timedelta(days=3)).strftime("%Y-%m-%d")
                except ValueError:
                    # å¦‚æœæ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤æ—¥æœŸ
                    check_in_date = (today + timedelta(days=1)).strftime("%Y-%m-%d")
                    check_out_date = (today + timedelta(days=3)).strftime("%Y-%m-%d")
                
                result = await search_google_hotels(
                    q=q,
                    check_in_date=check_in_date,
                    check_out_date=check_out_date
                )
                if isinstance(result, dict):
                    if "error" in result:
                        return f"é…’åº—æœç´¢å¤±è´¥: {result['error']}"
                    elif "properties" in result:
                        properties = result["properties"][:5]  # å–å‰5ä¸ªé…’åº—
                        hotel_list = []
                        for prop in properties:
                            title = prop.get('title', 'æœªçŸ¥é…’åº—')
                            price = prop.get('price', 'ä»·æ ¼æœªçŸ¥')
                            rating = prop.get('rating', 'è¯„åˆ†æœªçŸ¥')
                            hotel_list.append(f"{title} - {price} - è¯„åˆ†:{rating}")
                        return f"æ‰¾åˆ° {len(properties)} ä¸ªé…’åº—: {'; '.join(hotel_list)}"
                    else:
                        return f"é…’åº—æœç´¢å®Œæˆï¼Œç»“æœ: {list(result.keys())}"
                else:
                    return str(result)
            
            tools = [
                get_current_time_tool,
                search_google_tool,
                search_google_maps_tool,
                search_google_flights_tool,
                search_google_hotels_tool
            ]
            
            print(f"å¼‚æ­¥åŠ è½½äº† {len(tools)} ä¸ªæœ¬åœ°MCPå·¥å…·")
            return tools
            
        except Exception as e:
            print(f"å¼‚æ­¥åŠ è½½MCPå·¥å…·å¤±è´¥: {e}")
            return []
    
    def load_tools_sync(self) -> List[Any]:
        """åŒæ­¥åŠ è½½MCPå·¥å…·çš„åŒ…è£…å™¨"""
        try:
            # ä½¿ç”¨AsyncSyncWrapperæ¥é¿å…äº‹ä»¶å¾ªç¯é—®é¢˜
            tools = AsyncSyncWrapper.run_async_in_thread(self.load_tools_async)
            print(f"[DEBUG] MCPManager.load_tools_sync() è¿”å›çš„tools:")
            for idx, tool in enumerate(tools):
                print(f"  Tool {idx}: type={type(tool)}, name={getattr(tool, 'name', None)}, desc={getattr(tool, 'description', None)}, args_schema={getattr(tool, 'args_schema', None)}")
            return tools
        except Exception as e:
            print(f"åŒæ­¥åŠ è½½MCPå·¥å…·å¤±è´¥: {e}")
            return []

class AsyncSyncWrapper:
    """å¼‚æ­¥åŒæ­¥è½¬æ¢å·¥å…·"""
    @staticmethod
    def run_async_in_thread(async_func_or_coro, timeout: int = 60):
        """åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°æˆ–åç¨‹"""
        def sync_wrapper():
            if callable(async_func_or_coro):
                # å¦‚æœæ˜¯å‡½æ•°ï¼Œè°ƒç”¨å®ƒæ¥è·å¾—åç¨‹
                coro = async_func_or_coro()
            else:
                # å¦‚æœå·²ç»æ˜¯åç¨‹ï¼Œç›´æ¥ä½¿ç”¨
                coro = async_func_or_coro
            return asyncio.run(coro)
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(sync_wrapper)
            return future.result(timeout=timeout)

class StreamingUtils:
    """æµå¼è¾“å‡ºå·¥å…·"""
    @staticmethod
    def stream_text(text: str, chunk_size: int = 50) -> Generator[str, None, None]:
        """å°†æ–‡æœ¬åˆ†å—è¿›è¡Œæµå¼è¾“å‡º"""
        for i in range(0, len(text), chunk_size):
            yield text[i:i+chunk_size]

class ResponseExtractor:
    """å“åº”å†…å®¹æå–å·¥å…·"""
    @staticmethod
    def extract_agent_response(response: Dict[str, Any]) -> str:
        """ä»LangGraphæ™ºèƒ½ä½“å“åº”ä¸­æå–å†…å®¹"""
        if response and "messages" in response:
            last_message = response["messages"][-1]
            if hasattr(last_message, 'content'):
                return last_message.content
            elif isinstance(last_message, dict) and 'content' in last_message:
                return last_message['content']
        return "æŠ±æ­‰ï¼Œæœªèƒ½è·å–åˆ°æœ‰æ•ˆå“åº”ã€‚"

# =============================================================================
# 2. Refactored Agent Classes (The Workers)
# æ¯ä¸ªæ™ºèƒ½ä½“ç±»ç°åœ¨é€šè¿‡æ„é€ å‡½æ•°æ¥æ”¶å…¶ä¾èµ–é¡¹ï¼ˆå¦‚LLMå®ä¾‹å’Œå·¥å…·ï¼‰ï¼Œè€Œä¸æ˜¯è‡ªå·±åˆ›å»ºã€‚
# This is called Dependency Injection.
# =============================================================================

class InformationCollectorAgent:
    """ä¿¡æ¯æ”¶é›†æ™ºèƒ½ä½“ï¼ˆç»‘å®šMCPå·¥å…·ï¼‰"""
    def __init__(self, llm: ChatOpenAI, tools: List[Any]):
        self.llm = llm
        self.tools = tools
        self.agent = create_react_agent(self.llm, self.tools) if self.tools else None
        print(f"ä¿¡æ¯æ”¶é›†æ™ºèƒ½ä½“å·²åˆ›å»ºï¼Œå¯ç”¨å·¥å…·æ•°é‡: {len(self.tools)}")
    
    async def collect_information_async(self, user_request: str) -> str:
        if not self.agent:
            return f"ä¿¡æ¯æ”¶é›†æ™ºèƒ½ä½“ä¸å¯ç”¨ï¼ˆå·¥å…·åŠ è½½å¤±è´¥ï¼‰ï¼Œæ— æ³•å¤„ç†è¯·æ±‚: {user_request}"
        
        # print(f"\nğŸ” [MCPè°ƒè¯•] å¼€å§‹ä¿¡æ¯æ”¶é›†ï¼Œç”¨æˆ·è¯·æ±‚: {user_request}")
        print(f"ğŸ”§ [MCPè°ƒè¯•] å¯ç”¨å·¥å…·æ•°é‡: {len(self.tools)}")
        
        collector_request = f"{INFORMATION_COLLECTOR_PROMPT}\nç”¨æˆ·éœ€æ±‚:{user_request}"
        
        print(f"ğŸ“ [MCPè°ƒè¯•] å‘é€ç»™æ™ºèƒ½ä½“çš„æç¤ºè¯é•¿åº¦: {len(collector_request)} å­—ç¬¦")
        
        try:
            print(f"ğŸš€ [MCPè°ƒè¯•] å¼€å§‹è°ƒç”¨æ™ºèƒ½ä½“ï¼Œé¢„è®¡ä¼šä½¿ç”¨MCPå·¥å…·è¿›è¡Œæœç´¢...")
            # ä½¿ç”¨æ­£ç¡®çš„LangGraph 0.5.2 APIæ ¼å¼
            from langchain.schema import HumanMessage
            response = await self.agent.ainvoke({"messages": [HumanMessage(content=collector_request)]})
            
            # æå–å“åº”å†…å®¹
            response_content = ResponseExtractor.extract_agent_response(response)
            
            print(f"âœ… [MCPè°ƒè¯•] ä¿¡æ¯æ”¶é›†å®Œæˆï¼Œå“åº”é•¿åº¦: {len(response_content)} å­—ç¬¦")
            # print(f"ğŸ“Š [MCPè°ƒè¯•] å“åº”å†…å®¹é¢„è§ˆ: {response_content[:200]}...")
            
            return response_content
            
        except Exception as e:
            print(f"âŒ [MCPè°ƒè¯•] ä¿¡æ¯æ”¶é›†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return f"ä¿¡æ¯æ”¶é›†å¤±è´¥: {str(e)}"
    
    def get_response_stream(self, message: str):
        """è·å–å“åº”æµ"""
        try:
            full_response = AsyncSyncWrapper.run_async_in_thread(
                lambda: self.collect_information_async(message)
            )
            yield from StreamingUtils.stream_text(full_response)
        except Exception as e:
            yield f"å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}"

class PlannerAgent:
    """è¡Œç¨‹è§„åˆ’æ™ºèƒ½ä½“"""
    def __init__(self, llm_streaming: ChatOpenAI, llm_normal: ChatOpenAI):
        self.llm_streaming = llm_streaming
        self.llm_normal = llm_normal
        print("è¡Œç¨‹è§„åˆ’æ™ºèƒ½ä½“å·²åˆ›å»º")
        
    def get_response_stream(self, message: str, collected_info: str = "", conversation_history: list = None):
        """è·å–çœŸæµå¼å“åº”ï¼ˆæ”¯æŒå¯¹è¯è®°å¿†ï¼‰"""
        # æ„å»ºè§„åˆ’è¯·æ±‚å†…å®¹
        if collected_info:
            planning_content = f"ç”¨æˆ·åŸå§‹éœ€æ±‚ï¼š\n{message}\n\nä¿¡æ¯æ”¶é›†æ™ºèƒ½ä½“æä¾›çš„è¯¦ç»†ä¿¡æ¯ï¼š\n{collected_info}"
        else:
            planning_content = f"ç”¨æˆ·éœ€æ±‚ï¼š\n{message}"
        planning_content = planning_content + rag_search(message, top_k=3)['context']  # æ·»åŠ RAGæœç´¢ç»“æœ
        
        # æ„å»ºåŒ…å«å†å²è®°å¿†çš„æ¶ˆæ¯åˆ—è¡¨
        messages = [SystemMessage(content=ITINERARY_PLANNER_PROMPT)]
        
        # æ·»åŠ å†å²å¯¹è¯è®°å¿†ï¼ˆå…³äºæ—…è¡Œè§„åˆ’çš„ä¸Šä¸‹æ–‡ï¼‰
        if conversation_history:
            for msg in conversation_history[-8:]:  # æ—…è¡Œè§„åˆ’å¯èƒ½éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡ï¼Œä½†æ§åˆ¶æ•°é‡
                role = msg.get('role', '')
                content = msg.get('content', '')
                if role == 'user':
                    messages.append(HumanMessage(content=content))
                elif role == 'assistant':
                    messages.append(AIMessage(content=content))
        
        # æ·»åŠ å½“å‰è§„åˆ’è¯·æ±‚
        messages.append(HumanMessage(content=planning_content))
        
        # çœŸæµå¼è°ƒç”¨LLM
        for chunk in self.llm_streaming.stream(messages):
            if hasattr(chunk, 'content') and chunk.content:
                yield chunk.content

class PdfAgent:
    """PDFç”Ÿæˆæ™ºèƒ½ä½“"""
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.pdf_generator = PDFGeneratorTool()
        print("PDFç”Ÿæˆæ™ºèƒ½ä½“å·²åˆ›å»º")

    def generate_pdf(self, user_request: str, conversation_history: list = None) -> str:
        """ç”ŸæˆPDFæ—…æ¸¸æ”»ç•¥"""
        if not conversation_history:
            return "æš‚æ— å¯¹è¯å†å²è®°å½•ï¼Œæ— æ³•ç”ŸæˆPDFæŠ¥å‘Šã€‚"
        
        conversation_text = self._format_conversation_history(conversation_history)
        # summary = self._generate_conversation_summary(conversation_text, user_request)
        detailed_guide = self._generate_travel_guide(conversation_text, user_request)
        full_content = f"# æ—…è¡Œå¯¹è¯è®°å½•\n\n{conversation_text}\n\n---\n\n# è¯¦ç»†æ—…æ¸¸æ”»ç•¥\n\n{detailed_guide}"
        # pdf_result = self.pdf_generator.generate_travel_pdf(conversation_data=full_content, summary=summary, user_info="user") # user_info can be enhanced
        pdf_result = self.pdf_generator.generate_travel_pdf(conversation_data=full_content, summary=detailed_guide, user_info="user") # user_info can be enhanced
        return f"ğŸ“„{pdf_result}"
    
    def _format_conversation_history(self, conversation_history: list) -> str:
        return "\n\n".join([f"**{msg.get('role', 'æœªçŸ¥')}**: {msg.get('content', '')}" for msg in conversation_history])

    def _generate_conversation_summary(self, conversation_text: str, user_request: str) -> str:
        prompt = f"è¯·å¯¹ä»¥ä¸‹æ—…è¡Œå¯¹è¯è¿›è¡Œæ€»ç»“ï¼Œæå–å…³é”®ä¿¡æ¯ï¼š\n{conversation_text}\nå½“å‰è¯·æ±‚ï¼š{user_request}\næ€»ç»“åº”ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡200å­—ã€‚"
        response = self.llm.invoke([SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—…è¡Œé¡¾é—®ï¼Œæ“…é•¿æ€»ç»“å’Œæç‚¼ä¿¡æ¯ã€‚"), HumanMessage(content=prompt)])
        return response.content
        
    def _generate_travel_guide(self, conversation_text: str, user_request: str) -> str:
        prompt = f"åŸºäºä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„æ—…æ¸¸æ”»ç•¥ï¼š\n{conversation_text}\nå½“å‰éœ€æ±‚:{user_request}\nè¯·ç”Ÿæˆä¸€ä»½å®Œæ•´çš„æ—…æ¸¸æ”»ç•¥,ä½¿ç”¨èƒ½è®©pdfkitæ¸²æŸ“çš„markdownæ ¼å¼ã€‚"
        response = self.llm.invoke([SystemMessage(content=PDF_PROMPT), HumanMessage(content=prompt)])
        return response.content
    
    def get_response_stream(self, message: str, conversation_history: list):
        """è·å–å“åº”æµ"""
        full_response = self.generate_pdf(message, conversation_history)
        yield from StreamingUtils.stream_text(full_response)

class NormalAgent:
    """æ™®é€šå¯¹è¯æ™ºèƒ½ä½“"""
    def __init__(self, llm_streaming: ChatOpenAI):
        self.llm_streaming = llm_streaming
        print("æ™®é€šå¯¹è¯æ™ºèƒ½ä½“å·²åˆ›å»º")

    def get_response_stream(self, message: str, conversation_history: list = None):
        """è·å–çœŸæµå¼å“åº”ï¼ˆæ”¯æŒå¯¹è¯è®°å¿†ï¼‰"""
        # æ„å»ºåŒ…å«å†å²è®°å¿†çš„æ¶ˆæ¯åˆ—è¡¨
        messages = [SystemMessage(content=GENERAL_SYSTEM_PROMPT)]
        
        # æ·»åŠ å†å²å¯¹è¯è®°å¿†
        if conversation_history:
            for msg in conversation_history[-10:]:  # åªå–æœ€è¿‘10æ¡æ¶ˆæ¯é¿å…tokenè¿‡å¤š
                role = msg.get('role', '')
                content = msg.get('content', '')
                if role == 'user':
                    messages.append(HumanMessage(content=content))
                elif role == 'assistant':
                    messages.append(AIMessage(content=content))
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append(HumanMessage(content=message))
        
        # æµå¼ç”Ÿæˆå“åº”
        for chunk in self.llm_streaming.stream(messages):
            if hasattr(chunk, 'content') and chunk.content:
                yield chunk.content

# =============================================================================
# 3. AgentService (The Conductor)
# è¿™æ˜¯ä¸€ä¸ªæ–°çš„æ ¸å¿ƒç±»ï¼Œè´Ÿè´£æ‰€æœ‰ç»„ä»¶çš„åˆå§‹åŒ–ã€ç®¡ç†å’ŒååŒå·¥ä½œã€‚
# =============================================================================

class AgentService:
    """æ™ºèƒ½ä½“æœåŠ¡çš„ä¸­å¤®åè°ƒå™¨ï¼ˆæ‡’åŠ è½½æ¨¡å¼ï¼‰"""
    def __init__(self, redis_config=None):
        print("åˆå§‹åŒ– AgentService...")
        self.config = ConfigManager()
        self.llm_factory = LLMFactory(self.config)
        self.mcp_manager = MCPManager(self.config)
        
        # æ‡’åŠ è½½ï¼šä¸åœ¨åˆå§‹åŒ–æ—¶ç«‹å³åŠ è½½MCPå·¥å…·
        self._mcp_tools = None
        self._tools_loaded = False
        
        # åˆå§‹åŒ–Redisè®°å¿†ç®¡ç†å™¨
        if redis_config is None:
            redis_config = {}
        self.redis_memory_manager = get_redis_memory_manager(**redis_config)
        
        self.agent_sessions: Dict[str, Dict[str, Any]] = {}
        print("AgentService åˆå§‹åŒ–å®Œæˆï¼ˆä½¿ç”¨æ‡’åŠ è½½æ¨¡å¼ + Redisè®°å¿†ï¼‰ã€‚")

    @property
    def mcp_tools(self) -> List[Any]:
        """æ‡’åŠ è½½MCPå·¥å…·"""
        if not self._tools_loaded:
            print("é¦–æ¬¡è¯·æ±‚MCPå·¥å…·ï¼Œå¼€å§‹åŠ è½½...")
            self._mcp_tools = self.mcp_manager.load_tools_sync()
            self._tools_loaded = True
            print(f"MCPå·¥å…·åŠ è½½å®Œæˆï¼Œå…± {len(self._mcp_tools)} ä¸ªå·¥å…·")
        return self._mcp_tools

    def _create_agent_session(self, user_email: str, conv_id: str) -> Dict[str, Any]:
        """ä¸ºæ–°ç”¨æˆ·åˆ›å»ºä¸€å¥—å®Œæ•´çš„æ™ºèƒ½ä½“å’Œè®°å¿†"""
        print(f"ä¸ºç”¨æˆ· {user_email} åˆ›å»ºæ–°çš„æ™ºèƒ½ä½“ Session...")
        llm_normal = self.llm_factory.create_llm(streaming=False)
        llm_streaming = self.llm_factory.create_llm(streaming=True)
        
        # åˆ›å»ºä¼šè¯ç‰¹å®šçš„è®°å¿†
        session_key = f"{user_email}_{conv_id}"
        memory = RedisSimpleMemory(session_key, self.redis_memory_manager)
        
        return {
            'collector': InformationCollectorAgent(llm_normal, self.mcp_tools),  # è¿™é‡Œæ‰ä¼šè§¦å‘å·¥å…·åŠ è½½
            'planner': PlannerAgent(llm_streaming, llm_normal),
            'pdf_agent': PdfAgent(llm_normal),
            'normal_agent': NormalAgent(llm_streaming),
            'memory': memory,
        }

    def get_or_create_agent_session(self, user_email: str, conv_id: str) -> Dict[str, Any]:
        """è·å–æˆ–åˆ›å»ºç”¨æˆ·çš„æ™ºèƒ½ä½“ä¼šè¯"""
        session_key = f"{user_email}_{conv_id}"
        if session_key not in self.agent_sessions:
            self.agent_sessions[session_key] = self._create_agent_session(user_email, conv_id)
        return self.agent_sessions[session_key]

    def get_response_stream(self, user_message: str, user_email: str, agent_type: str = "general", conv_id: Optional[str] = None):
        """å¤„ç†ç”¨æˆ·è¯·æ±‚å¹¶è¿”å›å“åº”æµï¼ˆæ”¯æŒRedisè®°å¿†ï¼‰"""
        if not conv_id:
            raise ValueError("Conversation ID (conv_id) ä¸èƒ½ä¸ºç©º")
            
        full_response = ""
        try:
            session = self.get_or_create_agent_session(user_email, conv_id)
            memory: RedisSimpleMemory = session['memory']
            
            # è·å–å¯¹è¯å†å²è®°å¿†
            conversation_history = memory.messages

            if agent_type == "general":
                agent = session['normal_agent']
                answer = myanswer(user_message)
                if answer == '':
                    print(f"ğŸ” [SQLæŸ¥è¯¢] æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œä½¿ç”¨æ™®é€šå¯¹è¯æ™ºèƒ½ä½“å¤„ç†ã€‚")
                    generator = agent.get_response_stream(user_message, conversation_history)
                else:
                    sql_message = user_message + f"æœ¬åœ°æŸ¥æ‰¾åˆ°èµ„æ–™ä¿¡æ¯ï¼š{answer}"
                    print(f"ğŸ” [SQLæŸ¥è¯¢] æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œä½¿ç”¨SQLæ™ºèƒ½ä½“å¤„ç†ã€‚")
                    generator = agent.get_response_stream(sql_message, conversation_history)
                # print(sql_message)
            
            elif agent_type == "travel":
                if is_travel_planning_request(user_message):
                    # Multi-agent workflow with memory
                    collector_agent = session['collector']
                    planner_agent = session['planner']

                    '''
                    print(f"\nğŸ¯ [æ—…è¡Œè§„åˆ’] æ£€æµ‹åˆ°æ—…è¡Œè§„åˆ’è¯·æ±‚: {user_message}")
                    print(f"ğŸ”§ [æ—…è¡Œè§„åˆ’] ä¿¡æ¯æ”¶é›†æ™ºèƒ½ä½“å·¥å…·æ•°é‡: {len(collector_agent.tools)}")
                    print(f"ğŸ“… [æ—…è¡Œè§„åˆ’] å¼€å§‹ä¿¡æ¯æ”¶é›†é˜¶æ®µ...")
                    
                    print("æ—…è¡Œè§„åˆ’æµç¨‹: [1] ä¿¡æ¯æ”¶é›†ä¸­...")
                    '''

                    # ç›´æ¥ä½¿ç”¨åŒæ­¥æ–¹å¼è°ƒç”¨ä¿¡æ¯æ”¶é›†
                    collected_info = collector_agent.get_response_stream(user_message)
                    # æ”¶é›†å®Œæ•´å“åº”
                    collected_info_text = ""
                    for chunk in collected_info:
                        collected_info_text += chunk
                    
                    print(f"ğŸ“Š [æ—…è¡Œè§„åˆ’] ä¿¡æ¯æ”¶é›†å®Œæˆï¼Œæ”¶é›†åˆ°çš„ä¿¡æ¯é•¿åº¦: {len(collected_info_text)} å­—ç¬¦")
                    # print(f"ğŸ“‹ [æ—…è¡Œè§„åˆ’] æ”¶é›†åˆ°çš„ä¿¡æ¯é¢„è§ˆ: {collected_info_text[:300]}...")
                    print("æ—…è¡Œè§„åˆ’æµç¨‹: [2] å¼€å§‹æµå¼è¡Œç¨‹è§„åˆ’...")
                    generator = planner_agent.get_response_stream(user_message, collected_info, conversation_history)
                else:
                    # Simple travel question with memory
                    agent = session['normal_agent']
                    generator = agent.get_response_stream(user_message, conversation_history)

            elif agent_type == "pdf_generator":
                agent = session['pdf_agent']
                generator = agent.get_response_stream(user_message, conversation_history)
            
            else:
                raise ValueError(f"æœªçŸ¥çš„æ™ºèƒ½ä½“ç±»å‹: {agent_type}")

            # ä»ç”Ÿæˆå™¨æ¶ˆè´¹å†…å®¹å¹¶æ›´æ–°è®°å¿†
            for chunk in generator:
                full_response += chunk
                yield chunk
            
            # ä¿å­˜å¯¹è¯åˆ°Redisè®°å¿†ä¸­
            memory.add_message("user", user_message)
            memory.add_message("assistant", full_response)
            print(f"ğŸ’¾ å·²ä¿å­˜å¯¹è¯åˆ°Redisè®°å¿†ï¼Œå½“å‰è®°å¿†æ¡æ•°: {len(memory.messages)}")

        except Exception as e:
            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é—®é¢˜: {str(e)}"
            print(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}\n{traceback.format_exc()}")
            yield error_msg
            
            # å³ä½¿å‡ºé”™ä¹Ÿä¿å­˜åˆ°è®°å¿†ä¸­
            try:
                memory.add_message("user", user_message)
                memory.add_message("assistant", error_msg)
            except:
                pass
    
    def clear_user_sessions(self, user_email: str) -> int:
        """æ¸…é™¤ç”¨æˆ·çš„æ‰€æœ‰ä¼šè¯è®°å¿†"""
        cleared_count = 0
        keys_to_delete = []
        
        # æ‰¾åˆ°æ‰€æœ‰éœ€è¦æ¸…é™¤çš„ä¼šè¯
        for session_key in list(self.agent_sessions.keys()):
            if session_key.startswith(user_email):
                keys_to_delete.append(session_key)
        
        # æ¸…é™¤å†…å­˜ä¸­çš„ä¼šè¯
        for key in keys_to_delete:
            if key in self.agent_sessions:
                # æ¸…é™¤Redisè®°å¿†
                memory = self.agent_sessions[key]['memory']
                memory.clear()
                # åˆ é™¤ä¼šè¯
                del self.agent_sessions[key]
                cleared_count += 1
        
        print(f"å·²æ¸…é™¤ç”¨æˆ· {user_email} çš„ {cleared_count} ä¸ªä¼šè¯è®°å¿†")
        return cleared_count
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.redis_memory_manager.get_memory_stats()
        stats["active_agent_sessions"] = len(self.agent_sessions)
        return stats

# =============================================================================
# 4. Main Service Instance and Compatibility Layer (The Public API)
# æ‡’åŠ è½½å…¨å±€å®ä¾‹ï¼šåªåœ¨éœ€è¦æ—¶æ‰åˆ›å»º
# =============================================================================

_agent_service = None

def get_agent_service(redis_config=None) -> AgentService:
    """è·å–å…¨å±€AgentServiceå®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
    global _agent_service
    if _agent_service is None:
        _agent_service = AgentService(redis_config=redis_config)
    return _agent_service

# --- æ—§å‡½æ•°æ¥å£ï¼Œç°åœ¨ä»£ç†åˆ° AgentService ---
def get_agent_response_stream(user_message, user_email, agent_type="general", conv_id=None):
    """
    [å…¼å®¹æ€§æ¥å£] è·å–æ™ºèƒ½ä½“å“åº”æµã€‚
    æ­¤å‡½æ•°ç°åœ¨æ˜¯ AgentService.get_response_stream çš„ä¸€ä¸ªç®€å•åŒ…è£…ã€‚
    """
    return get_agent_service().get_response_stream(user_message, user_email, agent_type, conv_id)

def load_mcp_tools_async():
    """[å…¼å®¹æ€§æ¥å£] å¼‚æ­¥åŠ è½½MCPå·¥å…·"""
    return get_agent_service().mcp_manager.load_tools_async()

def load_mcp_tools_sync():
    """[å…¼å®¹æ€§æ¥å£] åŒæ­¥åŠ è½½MCPå·¥å…·çš„åŒ…è£…å™¨"""
    return get_agent_service().mcp_manager.load_tools_sync()

def clear_user_agent_sessions(user_email: str) -> int:
    """[æ–°æ¥å£] æ¸…é™¤ç”¨æˆ·çš„æ‰€æœ‰æ™ºèƒ½ä½“ä¼šè¯å’ŒRedisè®°å¿†"""
    return get_agent_service().clear_user_sessions(user_email)

def get_agent_memory_stats() -> Dict[str, Any]:
    """[æ–°æ¥å£] è·å–æ™ºèƒ½ä½“è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
    return get_agent_service().get_memory_stats()

def is_travel_planning_request(message: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºæ—…è¡Œè§„åˆ’è¯·æ±‚"""
    travel_keywords = ['æ—…è¡Œ', 'æ—…æ¸¸', 'å‡ºè¡Œ', 'è¡Œç¨‹', 'è§„åˆ’', 'è®¡åˆ’', 'æœºç¥¨', 'é…’åº—', 'ä½å®¿', 'æ™¯ç‚¹', 'è·¯çº¿',
                       'travel', 'trip', 'vacation', 'itinerary', 'plan', 'flight', 'hotel', 'attraction', 'route']
    return any(keyword in message.lower() for keyword in travel_keywords)
