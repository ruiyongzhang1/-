#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ¬åœ°çŸ¥è¯†åº“æœç´¢å‡½æ•°

ä¸“æ³¨äºæœ¬åœ°å‘é‡åº“æ£€ç´¢ï¼Œè¿”å›æ ¼å¼åŒ–çš„æœç´¢ç»“æœ
"""

import os
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

# å¯¼å…¥æœ¬åœ°å‘é‡åº“åˆå§‹åŒ–
from agent.RAG.knowledge_base import init_vectorstore

@dataclass
class SearchResult:
    """æœç´¢ç»“æœæ•°æ®ç»“æ„"""
    source: str  # "knowledge_base"
    title: str
    content: str
    score: Optional[float] = None
    metadata: Optional[Dict] = None

def search_local_knowledge(query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[SearchResult]:
    """
    æœ¬åœ°çŸ¥è¯†åº“æœç´¢å‡½æ•°
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        top_k: è¿”å›ç»“æœæ•°é‡
        score_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼Œè¶Šå°è¶Šä¸¥æ ¼ï¼‰
    
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    # åˆå§‹åŒ–å‘é‡åº“
    vectorstore = init_vectorstore()
    
    if not vectorstore:
        print("âŒ å‘é‡åº“æœªåˆå§‹åŒ–")
        return []
    
    try:
        # ä½¿ç”¨ç›¸ä¼¼åº¦æœç´¢
        docs_with_scores = vectorstore.similarity_search_with_score(
            query, 
            k=top_k
        )
        
        results = []
        for doc, score in docs_with_scores:
            # è¿‡æ»¤ä½ç›¸ä¼¼åº¦ç»“æœ
            if score <= score_threshold:
                continue
                
            # æå–æ–‡ä»¶å
            source_path = doc.metadata.get('source', 'Unknown')
            filename = os.path.basename(source_path) if source_path else 'Unknown'
            
            result = SearchResult(
                source="knowledge_base",
                title=f"ğŸ“š {filename}",
                content=doc.page_content,
                score=score,
                metadata=doc.metadata
            )
            results.append(result)
        
        print(f"âœ” æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
        return results
        
    except Exception as e:
        print(f"âŒ çŸ¥è¯†åº“æ£€ç´¢å¤±è´¥: {e}")
        return []

def format_search_results(results: List[SearchResult]) -> str:
    """
    å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸ºå¯è¯»å­—ç¬¦ä¸²
    
    Args:
        results: æœç´¢ç»“æœåˆ—è¡¨
    
    Returns:
        æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
    """
    if not results:
        return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
    
    formatted_parts = []
    for i, result in enumerate(results, 1):
        part = f"æ–‡æ¡£ {i}: {result.title}\n"
        part += f"ç›¸ä¼¼åº¦: {result.score:.3f}\n" if result.score else ""
        part += f"å†…å®¹: {result.content}\n"
        formatted_parts.append(part)
    
    return "\n" + "="*50 + "\n".join(formatted_parts)

def get_context_for_llm(results: List[SearchResult]) -> str:
    """
    ä¸ºLLMç”Ÿæˆä¸Šä¸‹æ–‡
    
    Args:
        results: æœç´¢ç»“æœåˆ—è¡¨
    
    Returns:
        LLMå¯ç”¨çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
    """
    if not results:
        return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æœ¬åœ°æ–‡æ¡£ä¿¡æ¯ã€‚"
    
    context_parts = []
    for i, result in enumerate(results, 1):
        context_parts.append(f"å‚è€ƒæ–‡æ¡£ {i}:\n{result.content}")
    
    return "\n\n".join(context_parts)

def rag_search(query: str, top_k: int = 3) -> Dict[str, Any]:
    """
    RAGæœç´¢æ¥å£ - ä¾›toolè°ƒç”¨
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        top_k: è¿”å›ç»“æœæ•°é‡
    
    Returns:
        åŒ…å«æœç´¢ç»“æœå’Œæ ¼å¼åŒ–ä¸Šä¸‹æ–‡çš„å­—å…¸
    """
    # print(f"ğŸ” RAGæœç´¢: {query}")
    
    # æœç´¢æœ¬åœ°çŸ¥è¯†åº“
    results = search_local_knowledge(query, top_k=top_k)
    
    # ç”Ÿæˆä¸Šä¸‹æ–‡
    context = get_context_for_llm(results)
    
    return {
        "query": query,
        "results": results,
        "context": context,
        "count": len(results)
    }